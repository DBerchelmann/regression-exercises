{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCALING EXERCISES\n",
    "\n",
    "<h5>Do your work for these exercises in a jupyter notebook named scaling. Use the telco dataset. Once you are finished, you may wish to repeat the exercises on another dataset for additional practice.</h5>\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.preprocessing\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "from wrangle import new_telco_data, acquire_telco, clean_telco, wrangle_telco\n",
    "from prepare import get_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------\n",
    "\n",
    "<h5>Apply the scalers we talked about in this lesson to your data and visualize the results in a way that can .</h5>\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab the data from SQL, use acquire to convert to .csv (if needed), finish with prepping with clean_telco(df)\n",
    "\n",
    "df = new_telco_data()\n",
    "df = acquire_telco()\n",
    "df = clean_telco(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 1695 entries, 0013-SMEOE to 9995-HOTOH\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   monthly_charges  1695 non-null   float64\n",
      " 1   tenure           1695 non-null   int64  \n",
      " 2   total_charges    1695 non-null   float64\n",
      "dtypes: float64(2), int64(1)\n",
      "memory usage: 53.0+ KB\n"
     ]
    }
   ],
   "source": [
    "# check data types of df to make sure the prepping happened\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled, validate_scaled, test_scaled = get_scaled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'monthly_charges'}>,\n",
       "        <AxesSubplot:title={'center':'tenure'}>],\n",
       "       [<AxesSubplot:title={'center':'total_charges'}>, <AxesSubplot:>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_scaled.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Let's visualize the data-set before splitting to view for any outliers</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"total_charges\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"tenure\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=\"monthly_charges\", data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.total_charges.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tenure.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.monthly_charges.hist(bins=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the split dataset that will be used for scaling purposes in this exercise\n",
    "\n",
    "train, validate, test  = wrangle_telco()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train.shape, validate.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Let's jump into the scaling section of the exercise</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the thing\n",
    "scaler = sklearn.preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fit on the training data\n",
    "# in a way, we treat our scalers like our ML models\n",
    "# we only .fit on the training data\n",
    "scaler.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = scaler.transform(train)\n",
    "validate_scaled = scaler.transform(validate)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn the numpy arrays into dataframes\n",
    "train_scaled = pd.DataFrame(train_scaled, columns=train.columns)\n",
    "validate_scaled = pd.DataFrame(validate_scaled, columns=train.columns)\n",
    "test_scaled = pd.DataFrame(test_scaled, columns=train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.legend(df)\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')\n",
    "plt.legend(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.tenure.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.monthly_charges.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.total_charges.hist(bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=\"tenure\", y=\"total_charges\", data=train_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Standard Scaler</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()\n",
    "# Note that we only call .fit with the training data,\n",
    "# but we use .transform to apply the scaling to all the data splits.\n",
    "scaler.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = scaler.transform(train)\n",
    "validate_scaled = scaler.transform(validate)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.legend(df)\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')\n",
    "plt.legend(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "<h4>Robust Scaler</h4>\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = scaler.transform(train)\n",
    "validate_scaled = scaler.transform(validate)\n",
    "test_scaled = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.legend(train)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled')\n",
    "plt.legend(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------\n",
    "\n",
    "<h3> Inverse Transform </h3>\n",
    "\n",
    "<h4>Apply the .inverse_transform method to your scaled data. Is the resulting dataset the exact same as the original data?</h4>\n",
    "\n",
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MinMax Inverse Transform</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = scaler.inverse_transform(train)\n",
    "validate_scaled = scaler.inverse_transform(validate)\n",
    "test_scaled = scaler.inverse_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.legend(train)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled - Inverse')\n",
    "plt.legend(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Standard Inverse Transform</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = scaler.inverse_transform(train)\n",
    "validate_scaled = scaler.inverse_transform(validate)\n",
    "test_scaled = scaler.inverse_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.legend(train)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled - Inverse')\n",
    "plt.legend(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Robust Scaler </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = sklearn.preprocessing.RobustScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = scaler.inverse_transform(train)\n",
    "validate_scaled = scaler.inverse_transform(validate)\n",
    "test_scaled = scaler.inverse_transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.legend(train)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled, bins=25, ec='black')\n",
    "plt.title('Scaled - Inverse')\n",
    "plt.legend(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "<h3> Quantile Transformer </h3>\n",
    "\n",
    "\n",
    "<h5>Read the documentation for sklearn's QuantileTransformer. Use normal for the output_distribution and apply this scaler to your data. Visualize the result of your data scaling.</h5>\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer(output_distribution='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_scaled = qt.transform(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = pd.DataFrame(train_scaled, columns=train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.legend(train)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled, bins=25, ec='black')\n",
    "plt.title('Quantile Transform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Use the QuantileTransformer, but omit the output_distribution argument. Visualize your results. What do you notice?</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt = QuantileTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qt.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_scaled = qt.transform(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled = pd.DataFrame(train_scaled, columns=train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(13, 6))\n",
    "plt.subplot(121)\n",
    "plt.hist(train, bins=25, ec='black')\n",
    "plt.title('Original')\n",
    "plt.legend(train)\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(train_scaled, bins=25, ec='black')\n",
    "plt.title('Quantile Transform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scaled.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the output distribution argurment is left out (the default becomes 'uniform') A uniform distribution shows an equal spread without peak as opposed to a normal distribution which will show the common 'bell curve'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
